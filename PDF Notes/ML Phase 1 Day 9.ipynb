{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVIFFBnYlQrom4JycNWRo6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h1> NATURAL LANGUAGE PROCESSING (N.L.P.)</h1>"],"metadata":{"id":"RWNDERiGGJDQ"}},{"cell_type":"markdown","source":["Natural Language is the daily use language which we humans use to communiate our thoughts and ideas to one another.<br> But now the task is to commnicate with a machine. This is the task we accomplish using N.L.P. We all have come across scenarios where N.L.P. is being used in real time like:\n","> Swiggy/Zomato Chat Bot.<br>\n","> Smart Replies in G-Mail, WhatsApp, LinkedIN, etc.\n","<br>\n","\n","Now N.L.P. is not just limited to talking to a machine, it involves a wide variety of tasks like:\n","- Classification of sentiments\n","- Information Extraction\n","- Information Retrival Systems\n","- Neural Machine Translation\n","\n","and many more.\n"],"metadata":{"id":"MLdI-pngGJAq"}},{"cell_type":"markdown","source":["A common misconception is there that `we can converse with a machine using a programing language.` But this is not true as, using a programming language we **instruct** the machine what to do, **Instructing is not the same as conversing**."],"metadata":{"id":"DFSm3F0QGI9a"}},{"cell_type":"markdown","source":["While we are proceeding towards making humans and machine interaction possible there are certain caveats that we need to address:\n","1. <u><b>Complexity of Representation</b></u>: Any huamn language that we consider will have its associated grammar rules, sentiment, sarcasm, etc. associated with it which makes it very complex in representation.\n","For e.g.\n","> in English : I am a student at Innomatics Research Labs<br>\n","> in French : Je suis étudiante à Innomatics Research Labs<br>\n","\n","In french the statement has a feminine nature to it which was not present in english. This is the complexity of language.\n","\n","2. <u><b>Ambiguity</b></u>: This problem arises on multiple scenarios, like say a word which can have entirely different meaning depending upon the situation or context in which it is being used. For e.g.<br>\n","- Cows are grazing at the `bank`. {Here the bank is river bank}\n","- I went to `bank` to deposit money. {Here the bank is a financial institution}\n","\n","Using N.L.P. techniques we can handle these problems upto a certain extent."],"metadata":{"id":"5T38239tGI6f"}},{"cell_type":"markdown","source":["<h2>Working with Text Data</h2>\n","\n","All the steps for using M.L. with text data will be the same as discussed previously with numerical and categorical data.<br>\n","The only difference will come in how we are going to perform `Data Cleaning` and `Data Transformation`"],"metadata":{"id":"x_q7aX_HGI3k"}},{"cell_type":"markdown","source":["To perform N.L.P. tasks using python, the most commonly used modules are:\n","- `nltk` (Natural Language Tool Kit)\n","- `spacy`\n","\n","For M.L. we will primarily focus on nltk and for D.L. based N.L.P. tasks we will use spacy."],"metadata":{"id":"VtXLkJuQGI0p"}},{"cell_type":"markdown","source":["<h2>N.L.P. Terminologies</h2>\n","\n","- Each row in a N.L.P. Dataset is called as a `Document`.\n","- The entire data which is a collection of Documents is called as a `Corpus`."],"metadata":{"id":"Ao4dZX37R6JV"}},{"cell_type":"markdown","source":["<h1> Data Transformation for Text </h1>"],"metadata":{"id":"AetGG-BDGIH9"}},{"cell_type":"markdown","source":["Text has to be transformed into numerical values so that the M.L. algorithms can understand it and give a model as output. Now here we will first see data transformation followed by data cleaning so that we can build upon the importance of data cleaning.<br>\n","There are many ways of transforming text into numerical values however we will be primarily looking at:\n","- Bag of Words (BoW)\n","- Term Frequency - Inverse Document Frequency (TF-IDF)\n","\n","Rest techniques will further explored in D.L."],"metadata":{"id":"pxaEYdAzGIE9"}},{"cell_type":"markdown","source":["<h2>Bag of Words (BoW)</h2>\n","\n","Bag of Words (BoW) is a popular technique in Natural Language Processing (NLP) used to represent text data. <br>It is a simple and effective way to convert text documents into numerical feature vectors, which can then be used as input to machine learning models. <br>The basic idea behind BoW is to represent a document as a multiset of its words, disregarding grammar and word order.<br>\n","It has a 2 step mechanism as following:\n","- Step 1: Learn the vocabulary (i.e. unique words) from the entire corpus and create the feature vector using the vocabulary.\n","- Step 2: Count the number of times each feature has appeared and create the Document Term Matrix (D.T.M.).\n","\n","Document Term Matrix is the numerical representation of the given corpus.\n","<br>\n","\n","<u><b>NOTE: AN IMPORTANT POINT TO KEEP IN MIND IS THAT WHEN BoW CREATES THE FEATURE VECTOR IT SORTS ALL THE FEATURES ALPHABETICALLY.</b></u>"],"metadata":{"id":"vSEEHAH6GIB4"}},{"cell_type":"markdown","source":["<h3>Example for BoW</h3>\n","\n","Consider the following two sentences:\n","\n","- Sentence 1: \"The cat sat on the mat.\"\n","- Sentence 2: \"The dog jumped over the fence.\"\n","\n","To create a BoW representation for these sentences, we first create a vocabulary containing all unique words in both sentences:\n","\n","- Vocabulary: [\"the\", \"cat\", \"sat\", \"on\", \"mat\", \"dog\", \"jumped\", \"over\", \"fence\"]\n","\n","Next, we represent each sentence as a vector where each element corresponds to the frequency of a word in the vocabulary:\n","\n","- Sentence 1 BoW: [1, 1, 1, 1, 1, 0, 0, 0, 0]\n","- Sentence 2 BoW: [1, 0, 0, 0, 0, 1, 1, 1, 1]\n","\n","<u><b>NOTE:\n","- BY NO MEANS IS BoW THE SAME AS ONE HOT ENCODING. O.H.E PURELY USES 0 AND 1 ONLY IN ITS ENCODING WHEREAS BoW USES THE FREQUENCY OF THE WORDS.\n","- DATA CLEANING IS VERY VERY IMPORTANT FOR BoW AS IF IT IS NOT DONE PROPERLY IT WILL LEAD TO CURSE OF DIMENSIONALITY.</b></u>"],"metadata":{"id":"XbefD-xuGH--"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","import pandas as pd\n","\n","# Sample sentences\n","sentences = [\n","    \"The cat sat on the mat.\",\n","    \"The dog jumped over the fence.\"\n","]\n","\n","# Create CountVectorizer object\n","vectorizer = CountVectorizer()\n","\n","# Fit and transform the sentences\n","X = vectorizer.fit_transform(sentences)\n","\n","print(\"Document Term Matrix\\n\",X)\n","# this output will be in the form of sparse matrix\n","\n","\n","# Get the vocabulary\n","vocabulary = vectorizer.get_feature_names_out()\n","print(\"\\n\\n Vocabulary learnt by BoW:\",vocabulary)\n","print()\n","\n","# Convert to array and print BoW representation\n","bow_representation = X.toarray()\n","for i, sentence in enumerate(sentences):\n","    print(f\"Sentence {i+1} BoW: {bow_representation[i]}\")\n","print()\n","\n","# Lets see the DTM in expanded form with vocabulary\n","df = pd.DataFrame(bow_representation, columns = vocabulary)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"D8wVy4WYTHrE","executionInfo":{"status":"ok","timestamp":1710224402692,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vaibhav Saran","userId":"14794725629799056560"}},"outputId":"526c0634-f633-42c7-ae00-b05220ec715f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Document Term Matrix\n","   (0, 8)\t2\n","  (0, 0)\t1\n","  (0, 7)\t1\n","  (0, 5)\t1\n","  (0, 4)\t1\n","  (1, 8)\t2\n","  (1, 1)\t1\n","  (1, 3)\t1\n","  (1, 6)\t1\n","  (1, 2)\t1\n","\n","\n"," Vocabulary learnt by BoW: ['cat' 'dog' 'fence' 'jumped' 'mat' 'on' 'over' 'sat' 'the']\n","\n","Sentence 1 BoW: [1 0 0 0 1 1 0 1 2]\n","Sentence 2 BoW: [0 1 1 1 0 0 1 0 2]\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["   cat  dog  fence  jumped  mat  on  over  sat  the\n","0    1    0      0       0    1   1     0    1    2\n","1    0    1      1       1    0   0     1    0    2"],"text/html":["\n","  <div id=\"df-28731613-361a-4051-a2de-56ce1779c377\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cat</th>\n","      <th>dog</th>\n","      <th>fence</th>\n","      <th>jumped</th>\n","      <th>mat</th>\n","      <th>on</th>\n","      <th>over</th>\n","      <th>sat</th>\n","      <th>the</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28731613-361a-4051-a2de-56ce1779c377')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-28731613-361a-4051-a2de-56ce1779c377 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-28731613-361a-4051-a2de-56ce1779c377');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5ca014db-2170-4a2e-8da3-df64e060b0a5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ca014db-2170-4a2e-8da3-df64e060b0a5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5ca014db-2170-4a2e-8da3-df64e060b0a5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"cat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dog\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jumped\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"on\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"over\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["<h3>Understanding Sparsity and Sparse Matrix</h3>\n","\n","- Sparsity: In layman terms you can say that sparsity is a problem which arises when in a large matrix you have most of the values as 0 and are not important. The problem is that if we directly store such huge matrices it will end up taking huge memory in storage as well as any computation done on them will also be very costly.\n","- Sparse Matrix: It is a solution to the above mentioned problem of sparsity. It solves the problem by representing the entire matrix as (row,column) pair with each pair having a corresponding non zero value.<br>\n","For e.g. In the above output `(0,8) 2` means that at 0th row and 8th column index the value is 2."],"metadata":{"id":"RgxtkwnHGH8M"}},{"cell_type":"markdown","source":["<h4>Considerations and Edge Cases</h4>\n","\n","- Case Sensitivity: By default, most implementations of BoW are case-sensitive. Consider converting all text to lowercase to ensure consistency.\n","- Stop Words: Common words like \"the\", \"and\", \"is\" often don't carry much meaning. Consider removing them from the vocabulary to focus on more informative terms.{We will see more about this in Data Cleaning}\n","- Tokenization: BoW relies on tokenization to split text into words. Consider different tokenization strategies based on your specific use case.\n","- Sparse Representation: BoW matrices can be very large and sparse, especially for large vocabularies or datasets. Consider using sparse matrix representations for memory efficiency.\n","- Handling Out-of-Vocabulary (OOV) Words: Decide how to handle words in test data that are not present in the training vocabulary. They can be ignored or represented separately.\n","- Word Order: BoW disregards word order and context, which may lead to loss of information in certain tasks like sentiment analysis or machine translation."],"metadata":{"id":"Lh8ZZ7tTGH5z"}},{"cell_type":"markdown","source":["<h2>N-Grams Approach</h2>\n","\n","The N-gram approach is a technique in Natural Language Processing (NLP) used to capture the structure and context of textual data by considering sequences of N consecutive words (or characters) as one word. N-grams are essentially contiguous sequences of N items (words, characters, etc.) extracted from a text.\n","\n","Lets see an example:\n","\n","- Consider the sentence: \"The cat sat on the mat.\"\n","  - Unigrams (1-grams): [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n","  - Bigrams (2-grams): [\"The cat\", \"cat sat\", \"sat on\", \"on the\", \"the mat\"]\n","  - Trigrams (3-grams): [\"The cat sat\", \"cat sat on\", \"sat on the\", \"on the mat\"]\n","  - 4-grams: [\"The cat sat on\", \"cat sat on the\", \"sat on the mat\"]"],"metadata":{"id":"iBatbzOhkZ54"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Sample sentences\n","sentences = [\n","    \"The cat sat on the mat.\",\n","    \"The dog jumped over the fence.\"\n","]\n","\n","# Create CountVectorizer object with ngram_range parameter\n","vectorizer = CountVectorizer(ngram_range=(1, 2))\n","# Change ngram_range for different N-grams\n","\n","# Fit and transform the sentences\n","X = vectorizer.fit_transform(sentences)\n","print(\"Document Term Matrix:\\n\",X)\n","print()\n","\n","# Get the vocabulary\n","vocabulary = vectorizer.get_feature_names_out()\n","print(\"\\nVocabulary Learnt:\\n\",vocabulary)\n","print()\n","\n","# Convert to array and print N-gram representation\n","ngram_representation = X.toarray()\n","\n","# Lets see the DTM in expanded form with vocabulary\n","df = pd.DataFrame(ngram_representation, columns = vocabulary)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"id":"gj7i31JalfH-","executionInfo":{"status":"ok","timestamp":1710229047547,"user_tz":-330,"elapsed":521,"user":{"displayName":"Vaibhav Saran","userId":"14794725629799056560"}},"outputId":"d8326572-227e-4497-8178-ddce2d3b799f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Document Term Matrix:\n","   (0, 14)\t2\n","  (0, 0)\t1\n","  (0, 12)\t1\n","  (0, 8)\t1\n","  (0, 7)\t1\n","  (0, 15)\t1\n","  (0, 1)\t1\n","  (0, 13)\t1\n","  (0, 9)\t1\n","  (0, 18)\t1\n","  (1, 14)\t2\n","  (1, 2)\t1\n","  (1, 5)\t1\n","  (1, 10)\t1\n","  (1, 4)\t1\n","  (1, 16)\t1\n","  (1, 3)\t1\n","  (1, 6)\t1\n","  (1, 11)\t1\n","  (1, 17)\t1\n","\n","\n","Vocabulary Learnt:\n"," ['cat' 'cat sat' 'dog' 'dog jumped' 'fence' 'jumped' 'jumped over' 'mat'\n"," 'on' 'on the' 'over' 'over the' 'sat' 'sat on' 'the' 'the cat' 'the dog'\n"," 'the fence' 'the mat']\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["   cat  cat sat  dog  dog jumped  fence  jumped  jumped over  mat  on  on the  \\\n","0    1        1    0           0      0       0            0    1   1       1   \n","1    0        0    1           1      1       1            1    0   0       0   \n","\n","   over  over the  sat  sat on  the  the cat  the dog  the fence  the mat  \n","0     0         0    1       1    2        1        0          0        1  \n","1     1         1    0       0    2        0        1          1        0  "],"text/html":["\n","  <div id=\"df-0c821075-d03f-44cb-9933-b33a14b21212\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cat</th>\n","      <th>cat sat</th>\n","      <th>dog</th>\n","      <th>dog jumped</th>\n","      <th>fence</th>\n","      <th>jumped</th>\n","      <th>jumped over</th>\n","      <th>mat</th>\n","      <th>on</th>\n","      <th>on the</th>\n","      <th>over</th>\n","      <th>over the</th>\n","      <th>sat</th>\n","      <th>sat on</th>\n","      <th>the</th>\n","      <th>the cat</th>\n","      <th>the dog</th>\n","      <th>the fence</th>\n","      <th>the mat</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c821075-d03f-44cb-9933-b33a14b21212')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0c821075-d03f-44cb-9933-b33a14b21212 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0c821075-d03f-44cb-9933-b33a14b21212');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5e54b9d4-7f4f-4a67-b1bd-8224824e4799\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e54b9d4-7f4f-4a67-b1bd-8224824e4799')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5e54b9d4-7f4f-4a67-b1bd-8224824e4799 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"cat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat sat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dog\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dog jumped\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jumped\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jumped over\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"on\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"on the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"over\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"over the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sat on\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the cat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the dog\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the fence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the mat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["<b><u>NOTE: IN THE ABOVE CODE IF YOU GIVE THE `ngram_range = (1,2)` THEN THE VOCABULARY WILL CONTAIN 1 GRAM + 2 GRAM VOCABULARY.<br>\n","HOWEVER IF YOU WANT ONLY 2 GRAM VOCABULARY THEN GIVE `ngram_range=(2,2)`.</u></b>"],"metadata":{"id":"GjBWCv9nkZ35"}},{"cell_type":"markdown","source":["<h2>ADVANTAGES AND DISADVANTAGES OF BAG OF WORDS</h2>\n","\n","1. Advantages\n","  - It is simple to understand and implement like One Hot Encoding *{BoW is replacing 0 & 1 with the count of the feature in the given document}*.\n","  - It gives a fixed length encoding for any sequence of arbitrary length as long as the vocabulary does not change.\n","  - Documents with same word/vocabulary will have similar representation. So if two documents have a similar vocabulary, they will be closer to each other in the vector space and vice-versa.\n","\n","2. Disadvantages\n","  - 1) The size of feature vector increases with the increase in the size of vocabulary. Thus making sparsity a continuing problem.\n","      - Solution: It can be tackled by limiting the frequency of the most frequent words.\n","  - 2) It does not capture the similarity between differnt words that mean the same thing i.e. **Semantic Meaning is not captured.**\n","    - **Is there an algorithm to solve the above 2 problems?**\n","      - Yes, it is *word2vec algorithm*. {will be covered in D.L.}\n","\n","  - 3) BoW representation does not have any way to handle O.O.V. (Out of Vocabulary) words.\n","    - O.O.V. are the new words which were not seen in the corpus that was used to build the vectorizer in the training phase.\n","  - 4) Word order information is lost in the BoW representation.\n","    - Solution: One Way to control is to use N-Grams approach.\n","      - **Is there a way to solve problem 3 and 4 ?**\n","        - Yes, it is *BERT Algorithm* (Bi Directional Encoder Representation from Transformer) {will be covered in D.L.}\n","  - 5) BoW representation suffers from curse of dimensionality."],"metadata":{"id":"ZbUVsj_NpZb3"}},{"cell_type":"markdown","source":["<h2>Term Frequency - Inverse Document Frequency (TF-IDF)</h2>\n","\n","TF-IDF is another popular technique in Natural Language Processing (NLP) used to represent text data. It reflects how important a word is to a document within a collection of documents. TF-IDF combines two metrics: term frequency (TF), which measures the frequency of a term in a document, and inverse document frequency (IDF), which measures how rare a term is across documents in a corpus.\n","<br>\n","\n","The working of TF-IDF can be divided into 2 steps:\n","- Step 1: Learn the vocabulary (i.e. unique words) from the entire corpus and create the feature vector using the vocabulary.\n","- Step 2: For each feature in each document compute the TF-IDF value.\n","\n","\n","$$ TF \\ IDF = TF(word_i, doc_j) * IDF(word_i, corpus) $$\n","\n","$$ TF(word_i, doc_j) = \\frac{No \\ of \\ time \\ word_i \\ occurs \\ in \\ doc_j}{Total \\ no \\ of \\ words \\ in \\ doc_j} $$\n","\n","$$ IDF(word_i, corpus) = \\log_n(\\frac{No \\ of \\ docs \\ in \\ corpus}{No \\ of \\ docs \\ which \\ contains \\ word_i}) $$\n"],"metadata":{"id":"3BQ3wq3iGH3U"}},{"cell_type":"markdown","source":["Lets take a look at an example and see the working:<br>\n","\n","Consider a corpus containing three documents:\n","\n","- Document 1: \"The cat sat on the mat.\"\n","- Document 2: \"The dog jumped over the fence.\"\n","- Document 3: \"The cat and the dog are friends.\"\n","\n","To compute TF-IDF for the term \"cat\" in Document 1:\n","\n","- Term Frequency (TF): Number of times \"cat\" appears in Document 1 = 1\n","- Inverse Document Frequency (IDF): log(N / df), where N is the total number of documents and df is the number of documents containing the term \"cat\" (df = 2 in this case)\n","- TF-IDF = TF * IDF"],"metadata":{"id":"WJ16FZGDGH1F"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd\n","\n","# Sample documents\n","documents = [\n","    \"The cat sat on the mat.\",\n","    \"The dog jumped over the fence.\",\n","    \"The cat and the dog are friends.\"\n","]\n","\n","# Create TfidfVectorizer object\n","vectorizer = TfidfVectorizer()\n","\n","# Fit and transform the documents\n","X = vectorizer.fit_transform(documents)\n","print(\"Document Term Matrix:\\n\",X) # Output will be a sparse matrix\n","print()\n","\n","# Get the vocabulary\n","vocabulary = vectorizer.get_feature_names_out()\n","print(\"\\n Vocabulary learnt:\\n\",vocabulary)\n","print()\n","\n","# Convert to array and print TF-IDF representation\n","tfidf_representation = X.toarray()\n","\n","# Lets see the DTM in expanded form with vocabulary\n","df = pd.DataFrame(tfidf_representation, columns = vocabulary)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":543},"id":"iK_v1hsxi30T","executionInfo":{"status":"ok","timestamp":1710228364701,"user_tz":-330,"elapsed":472,"user":{"displayName":"Vaibhav Saran","userId":"14794725629799056560"}},"outputId":"c543d20a-4048-44f2-e264-81305c8d3455"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Document Term Matrix:\n","   (0, 7)\t0.44839402160692654\n","  (0, 8)\t0.44839402160692654\n","  (0, 10)\t0.44839402160692654\n","  (0, 2)\t0.3410152109911944\n","  (0, 11)\t0.5296574648148862\n","  (1, 4)\t0.44839402160692654\n","  (1, 9)\t0.44839402160692654\n","  (1, 6)\t0.44839402160692654\n","  (1, 3)\t0.3410152109911944\n","  (1, 11)\t0.5296574648148862\n","  (2, 5)\t0.42439575294071896\n","  (2, 1)\t0.42439575294071896\n","  (2, 0)\t0.42439575294071896\n","  (2, 3)\t0.32276390910429226\n","  (2, 2)\t0.32276390910429226\n","  (2, 11)\t0.5013099366829596\n","\n","\n"," Vocabulary learnt:\n"," ['and' 'are' 'cat' 'dog' 'fence' 'friends' 'jumped' 'mat' 'on' 'over'\n"," 'sat' 'the']\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["        and       are       cat       dog     fence   friends    jumped  \\\n","0  0.000000  0.000000  0.341015  0.000000  0.000000  0.000000  0.000000   \n","1  0.000000  0.000000  0.000000  0.341015  0.448394  0.000000  0.448394   \n","2  0.424396  0.424396  0.322764  0.322764  0.000000  0.424396  0.000000   \n","\n","        mat        on      over       sat       the  \n","0  0.448394  0.448394  0.000000  0.448394  0.529657  \n","1  0.000000  0.000000  0.448394  0.000000  0.529657  \n","2  0.000000  0.000000  0.000000  0.000000  0.501310  "],"text/html":["\n","  <div id=\"df-025ccf51-d152-44d7-a4a9-9c84d26f3d81\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>and</th>\n","      <th>are</th>\n","      <th>cat</th>\n","      <th>dog</th>\n","      <th>fence</th>\n","      <th>friends</th>\n","      <th>jumped</th>\n","      <th>mat</th>\n","      <th>on</th>\n","      <th>over</th>\n","      <th>sat</th>\n","      <th>the</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.341015</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.448394</td>\n","      <td>0.448394</td>\n","      <td>0.000000</td>\n","      <td>0.448394</td>\n","      <td>0.529657</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.341015</td>\n","      <td>0.448394</td>\n","      <td>0.000000</td>\n","      <td>0.448394</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.448394</td>\n","      <td>0.000000</td>\n","      <td>0.529657</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.424396</td>\n","      <td>0.424396</td>\n","      <td>0.322764</td>\n","      <td>0.322764</td>\n","      <td>0.000000</td>\n","      <td>0.424396</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.501310</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-025ccf51-d152-44d7-a4a9-9c84d26f3d81')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-025ccf51-d152-44d7-a4a9-9c84d26f3d81 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-025ccf51-d152-44d7-a4a9-9c84d26f3d81');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1b2127ad-2768-4fd1-a028-f87ed3953a29\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b2127ad-2768-4fd1-a028-f87ed3953a29')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1b2127ad-2768-4fd1-a028-f87ed3953a29 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"and\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24502500220325799,\n        \"min\": 0.0,\n        \"max\": 0.42439575294071896,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.42439575294071896,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"are\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24502500220325799,\n        \"min\": 0.0,\n        \"max\": 0.42439575294071896,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.42439575294071896,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19183370627022225,\n        \"min\": 0.0,\n        \"max\": 0.3410152109911944,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3410152109911944,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dog\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19183370627022225,\n        \"min\": 0.0,\n        \"max\": 0.3410152109911944,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.3410152109911944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2588804090777779,\n        \"min\": 0.0,\n        \"max\": 0.44839402160692654,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.44839402160692654,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"friends\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24502500220325799,\n        \"min\": 0.0,\n        \"max\": 0.42439575294071896,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.42439575294071896,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jumped\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2588804090777779,\n        \"min\": 0.0,\n        \"max\": 0.44839402160692654,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.44839402160692654,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2588804090777779,\n        \"min\": 0.0,\n        \"max\": 0.44839402160692654,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.44839402160692654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"on\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2588804090777779,\n        \"min\": 0.0,\n        \"max\": 0.44839402160692654,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.44839402160692654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"over\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2588804090777779,\n        \"min\": 0.0,\n        \"max\": 0.44839402160692654,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.44839402160692654,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2588804090777779,\n        \"min\": 0.0,\n        \"max\": 0.44839402160692654,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.44839402160692654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016366452997828275,\n        \"min\": 0.5013099366829596,\n        \"max\": 0.5296574648148862,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5013099366829596,\n          0.5296574648148862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["<h4>Considerations and Edge Cases</h4>\n","\n","- Normalization: TF-IDF values are often normalized to prevent bias towards longer documents.\n","- Stop Words: Similar to BoW, consider removing common stop words to improve the quality of TF-IDF representations.\n","- Tokenization: Like BoW, TF-IDF relies on tokenization. Ensure consistent tokenization strategies across documents.\n","- Sparse Representation: TF-IDF matrices can also be large and sparse. Consider using sparse matrix representations for efficiency.\n","- Handling Out-of-Vocabulary (OOV) Words: Decide how to handle OOV words, similar to BoW.\n","- Smoothing: Consider using smoothing techniques to handle terms that may have zero IDF due to not appearing in the entire corpus."],"metadata":{"id":"nejeTtc0GHy4"}},{"cell_type":"markdown","source":["<h1> Cleaning Text Data</h1>"],"metadata":{"id":"gL4vS38gGIxu"}},{"cell_type":"markdown","source":["The text data in general which is made available for any N.L.P. task has a lot unnecessary elements which we needs to clean out. The benefit is that we only keep the relevant and important information and discard the rest of it."],"metadata":{"id":"Uas8CossGIu7"}},{"cell_type":"markdown","source":["There are a lot of steps which can be performed for a specific N.L.P. task but some of the most common steps are:\n","\n","1. <b><u>Converting all text data to lower case.</u></b>\n","2. <b><u>Removing all the special characters.</u></b>\n","3. <b><u>Removing the stopwords.</u></b>\n","4. <b><u>Converting every word to its root form.</u></b>\n","\n","Lets explore these steps in detail"],"metadata":{"id":"GTGSew68GIr5"}},{"cell_type":"markdown","source":["<h3><b><u>1. Converting All Text Data To Lower Case</u></b></h3>\n","\n","This is the first step performed for cleaning the text with a very specific reason because the machine treats, `\"Adam\"` and `\"adam\"` as two separate strings/words; whereas we know that it is the same thing.<br> In order to ensure that the machine/model also understands the same we convert the text to lower case."],"metadata":{"id":"wWLZoOe7GIou"}},{"cell_type":"markdown","source":["<h3><b><u>2. Removing All The Special Characters</u></b></h3>\n","\n","Special characters like`.,\"\";` etc. are removed because these symbols are just to enhance the readability for humans and are not contributing any significant meaning in the sentence.<br>\n","\n","For e.g.: `I told them, \"My name is Adam\".`; this sentence is the way in which humans write and are accustomed to reading and interpreting it.<br>\n","Now after we remove the special characters and convert to lower case:<br>\n","`i told them my name is adam`; this sentence is also conveying the same meaning as the previous one.<br> In N.L.P. the meaning and the understanding of the intent is more important not the way its written.<br>*{In advanced N.L.P. techniques we will see that even the punctuations and presentation of output can be taken care of but that is a topic for later modules.}*"],"metadata":{"id":"Wci_WJ4RGIlo"}},{"cell_type":"markdown","source":["<b><u>NOTE: THE ABOVE TWO STEPS WORK ON CHARACTER LEVEL TOKENS</u></b>"],"metadata":{"id":"CZonbHR_oem6"}},{"cell_type":"markdown","source":["<h3><b><u>3. Removing Stopwords</u></b></h3>\n","\n","`Stopwords` are those words which enhance the human readability of a sentence, and removing them does not change the core meaning of the sentence. e.g. of stopwords, I, me, am, the, etc.<br>\n","For e.g.\n","- `i told them my name is adam`. the core meaning of this sentence is that a name was told as adam.\n","- After removing stopwords, `told name adam`. Here also the core meaning is that a name was told as adam.\n","\n","When dealing in NLP the most important thing is to ensure that the model gets the core meaning of the sentence. Post which you can make a sentence readable, translate, etc. but all this can only happen if the core meaning is understood correctly.<br>\n","\n","Another advantage of removing the stopwords is that it helps in countering `Curse of Dimensionality` as after removing stopwords the total number of words is reduced; which in turn means we have to get numerical representation for less number of words as a result less dimensions. **All this happens without loosing the core crux of the sentence.**"],"metadata":{"id":"Eb9FfOqmGIiu"}},{"cell_type":"markdown","source":["<h3><b><u>4. Converting Every Word To Its Root Form</u></b></h3>\n","\n","In order to convert a given word to its root form the techniques which we will be using are:\n","- Stemming\n","- Lemmatization\n","\n","Reducing words to their root form is important for several reasons:\n","\n","1. **Text Normalization**: It simplifies and standardizes words, which is crucial for processing and understanding text data¹.\n","2. **Reduces Complexity**: By converting words to their base form, it helps in reducing the complexity of the text, making it easier for algorithms to process¹.\n","3. **Improves Accuracy**: It can improve the accuracy of various NLP tasks like text classification, information retrieval, and text summarization by reducing the dimensionality of the data².\n","4. **Facilitates Search**: It allows search algorithms to equate different forms of a word, enhancing the ability to find relevant results².\n","5. **Efficient Language Processing**: It plays a role in making language processing more efficient and intelligent by bringing words with similar meanings to their root form³.\n","\n","Now, lets understand stemming and lemmatization:\n","- **Stemming** usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. For example, the stem of the words \"running\", \"runner\", and \"ran\" is \"run\".\n","\n","- **Lemmatisation**, on the other hand, usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma. For instance, the lemma of \"was\" is \"be\", and the lemma of \"mice\" is \"mouse\".\n","\n","- Here's an example sentence: `\"The striped bats are hanging on their feet for best.\"`\n","\n","- **Stemming** might reduce the sentence to: `\"The strip bat are hang on their feet for best.\"`\n","- **Lemmatisation** would result in: `\"The striped bat be hang on their foot for good.\"`\n","\n","<b><u>NOTE</b></u>:\n","- Stemming can sometimes create non-words, as in \"strip\" from \"striped\", whereas lemmatisation attempts to return real words.\n","- Lemmatisation is more sophisticated and considers the context of the word in order to determine its base form.\n","- Stemming is faster than lemmatization as it does not worry about humany readability of root words.\n","- The speed of stemming comes at the cost of being very brutal on the word as it bluntly chops of extra parts to reduce a word to its root form.\n","\n","<h4>Errors Related To Stemming</h4>\n","\n","- Overstemming: This happens when two or more unrelated words result in the same stem.\n","- Understemming: This happens when two or more related words result in different stem.\n","\n","<h4>Variants of Stemming</h4>\n","\n","- `Porter Stemmer`: It only works for english language and may or may not be linguistically correct in giving root words.\n","- `Snowball Stemmer`: It is an upgraded version of `Porter Stemmer` as it is able to suport multiple languages and is much better at getting root forms of words.\n","- `Lancaster Stemmer`: It utilizes an iterative approach to convert words to their root form. Of the 3 it is the most aggresive stemmer which leads it to more often than not with the issue of overstemming. Lancaster Stemmer is also for english language only.\n","\n","<h4><b><u>When to use stemming and when to use lemmatization?</u></b></h4>\n","\n","- Use `stemming` if the task is like: Building Search Engines, Working with information retrival systems, etc.\n","\n","- Use `lemmatization` if the task is like: Sentiment Analysis of reviews, Language Modelling, etc."],"metadata":{"id":"zP_Z1-iKGIf8"}},{"cell_type":"markdown","source":["<b><u>NOTE: THE ABOVE 2 STEPS WORK ON WORD LEVEL TOKENS</u></b>"],"metadata":{"id":"2vOWYAvbo_8r"}},{"cell_type":"markdown","source":["<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n"],"metadata":{"id":"h_FviKIM9fPk"}},{"cell_type":"code","source":[],"metadata":{"id":"Zt5NF28I9qy-"},"execution_count":null,"outputs":[]}]}